{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71385cec",
   "metadata": {},
   "source": [
    "\n",
    "# Appraisal Scope — Reorganized Analysis Notebook\n",
    "\n",
    "This notebook has been reorganized into a clean, reproducible flow:\n",
    "\n",
    "1) **Setup & Config**  \n",
    "2) **Extract Data** (from GBQ/CSV/SQL/etc.)  \n",
    "3) **Combine DataFrames** (joins, alignment, target/feature selection)  \n",
    "4) **Feature Engineering** (lags, rolling stats, seasonal flags, YoY/MoM)  \n",
    "5) **Visual EDA** (time series charts, *dual‑axis* helper across all variables)  \n",
    "6) **Statistical Tests** (correlation, ADF, ACF/PACF, normality, Granger causality)  \n",
    "7) **Models** (OLS, SARIMAX, Weighted Lag, XGBoost, Naive 12‑lag + 3‑mo YoY growth)  \n",
    "8) **Evaluation & Model Selection** (RMSE/MAE/MAPE/SMAPE, backtests)  \n",
    "9) **Save Artifacts** (CSVs, charts, model summaries)\n",
    "\n",
    "> Notes:  \n",
    "- Update paths and variable names as needed.  \n",
    "- XGBoost import is optional (gracefully skipped if unavailable).  \n",
    "- Keep target column named `y` for simplicity (rename in Section 3).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f3b236",
   "metadata": {},
   "source": [
    "## 1) Setup & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5697739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standard\n",
    "import os, sys, math, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data + Stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Time series & stats tests\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as tsa\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox, het_breuschpagan, normal_ad\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "\n",
    "# Machine learning\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    XGB_AVAILABLE = True\n",
    "except Exception:\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "# Display options\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "# Random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Helper: metrics\n",
    "def smape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
    "    denom = np.where(denom == 0, 1.0, denom)\n",
    "    return np.mean(np.abs(y_pred - y_true) / denom) * 100\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    denom = np.where(y_true == 0, 1.0, y_true)\n",
    "    return np.mean(np.abs((y_true - y_pred) / denom)) * 100\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(np.array(y_true) - np.array(y_pred)))\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return math.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99585cf",
   "metadata": {},
   "source": [
    "## 2) Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf027851",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Replace this block with your real extractor (GBQ/SQL/API). ===\n",
    "# For now, read from CSVs as an example.\n",
    "# Expected: a time column `date` (monthly) and at least one target column (e.g., 'total_cases_opened').\n",
    "# Example:\n",
    "# df_target = pd.read_csv('/mnt/data/appscope_target.csv', parse_dates=['date'])\n",
    "# df_drivers = pd.read_csv('/mnt/data/appscope_drivers.csv', parse_dates=['date'])\n",
    "\n",
    "df_target = pd.DataFrame({\n",
    "    'date': pd.date_range('2022-01-01', periods=36, freq='MS'),\n",
    "    'total_cases_opened': (np.random.rand(36)*1000 + 3000).round(0)\n",
    "})\n",
    "df_drivers = pd.DataFrame({\n",
    "    'date': pd.date_range('2022-01-01', periods=36, freq='MS'),\n",
    "    'UNRATE': np.random.rand(36)*5 + 3,\n",
    "    'MORTGAGE30US': np.random.rand(36)*2 + 5,\n",
    "    'orders': (np.random.rand(36)*12000+40000).round(0)\n",
    "})\n",
    "df_target.head(), df_drivers.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e49921",
   "metadata": {},
   "source": [
    "## 3) Combine DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43211160",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Align by month start and set the target as `y`\n",
    "df = pd.merge(df_target, df_drivers, on='date', how='inner').sort_values('date')\n",
    "df = df.set_index('date')\n",
    "df['y'] = df['total_cases_opened']\n",
    "df = df.drop(columns=['total_cases_opened'])\n",
    "\n",
    "print(\"Combined shape:\", df.shape)\n",
    "display(df.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2acfced",
   "metadata": {},
   "source": [
    "## 4) Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a023ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lags (12), rolling means, seasonal dummies, YoY growth (3-month YoY variant)\n",
    "for lag in range(1, 13):\n",
    "    df[f'y_lag{lag}'] = df['y'].shift(lag)\n",
    "\n",
    "# Driver lags\n",
    "for col in [c for c in df.columns if c not in ['y'] and not c.startswith('y_lag')]:\n",
    "    for lag in [1,3,6,12]:\n",
    "        df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
    "\n",
    "# Rolling features on y\n",
    "df['y_roll3'] = df['y'].rolling(3).mean()\n",
    "df['y_roll6'] = df['y'].rolling(6).mean()\n",
    "df['y_roll12'] = df['y'].rolling(12).mean()\n",
    "\n",
    "# Seasonality\n",
    "df['month'] = df.index.month\n",
    "df = pd.get_dummies(df, columns=['month'], prefix='m', drop_first=True)\n",
    "\n",
    "# 3-month YoY growth: (y_t - y_{t-12}) / y_{t-12} averaged over last 3 months\n",
    "df['y_yoy'] = (df['y'] - df['y'].shift(12)) / df['y'].shift(12)\n",
    "df['y_yoy_3m'] = df['y_yoy'].rolling(3).mean()\n",
    "\n",
    "display(df.tail(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56af666f",
   "metadata": {},
   "source": [
    "## 5) Visual EDA — Time Series & Dual‑Axis Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda6c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper to dual-axis plot any driver vs target y\n",
    "def plot_dual_axis(df, driver_col, target_col='y', title=None):\n",
    "    if title is None:\n",
    "        title = f\"{driver_col} vs {target_col}\"\n",
    "    ax = df[[target_col]].plot(figsize=(10,4))\n",
    "    df[[driver_col]].plot(ax=ax, secondary_y=True)\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot y\n",
    "df[['y']].plot(figsize=(10,4), title='Target y'); plt.grid(True); plt.show()\n",
    "\n",
    "# Plot all drivers (non-lag, non-dummy) against y as dual-axis\n",
    "base_cols = [c for c in df.columns if not c.startswith('y_lag') and not c.startswith('m_')\n",
    "             and c not in ['y','y_roll3','y_roll6','y_roll12','y_yoy','y_yoy_3m']]\n",
    "for col in base_cols:\n",
    "    plot_dual_axis(df, col, target_col='y', title=f\"{col} vs y\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ffa8f2",
   "metadata": {},
   "source": [
    "## 6) Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b39231",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from itertools import combinations\n",
    "import statsmodels.tsa.stattools as tsast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Correlation matrix (Pearson) for base columns + y\n",
    "corr_cols = ['y'] + base_cols\n",
    "corr = df[corr_cols].dropna().corr(method='pearson')\n",
    "display(corr)\n",
    "\n",
    "# ADF test on y\n",
    "adf_res = adfuller(df['y'].dropna(), autolag='AIC')\n",
    "print(\"ADF Statistic:\", adf_res[0])\n",
    "print(\"p-value:\", adf_res[1])\n",
    "print(\"Critical Values:\", adf_res[4])\n",
    "\n",
    "# Autocorrelation and partial autocorrelation\n",
    "series = df['y'].dropna()\n",
    "lags_to_show = min(24, len(series)-1) if len(series) > 1 else 1\n",
    "acf_vals = acf(series, nlags=lags_to_show, fft=True)\n",
    "pacf_vals = pacf(series, nlags=lags_to_show, method='ywunbiased')\n",
    "print(\"ACF (first 10):\", np.round(acf_vals[:10],3))\n",
    "print(\"PACF (first 10):\", np.round(pacf_vals[:10],3))\n",
    "\n",
    "# Normality tests\n",
    "jb_stat, jb_p, _, _ = jarque_bera(series)\n",
    "print(f\"Jarque-Bera: stat={jb_stat:.3f}, p={jb_p:.5f}\")\n",
    "ad_stat, ad_p = normal_ad(series)\n",
    "print(f\"Anderson-Darling normality (approx): stat={ad_stat:.3f}, p={ad_p:.5f}\")\n",
    "\n",
    "# Granger causality tests (each driver -> y), maxlag up to 12 where feasible\n",
    "maxlag = max(1, min(12, len(df.dropna())//4))\n",
    "granger_results = {}\n",
    "for col in base_cols:\n",
    "    try:\n",
    "        out = tsast.grangercausalitytests(df[[ 'y', col ]].dropna(), maxlag=maxlag, verbose=False)\n",
    "        # collect min p-value across lags for F-test\n",
    "        pvals = [out[lag][0]['ssr_ftest'][1] for lag in out.keys()]\n",
    "        granger_results[col] = float(np.min(pvals))\n",
    "    except Exception:\n",
    "        granger_results[col] = np.nan\n",
    "\n",
    "granger_df = pd.DataFrame({'driver': list(granger_results.keys()), 'min_pvalue': list(granger_results.values())}).sort_values('min_pvalue')\n",
    "display(granger_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350f1631",
   "metadata": {},
   "source": [
    "## 7) Modeling — OLS, SARIMAX, Weighted Lag, XGB, Naive(12‑lag)+YoY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21701bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train/test split (last 6 months as test by default)\n",
    "horizon = 6\n",
    "data = df.dropna().copy()\n",
    "if len(data) < horizon + 13:\n",
    "    horizon = max(1, min(3, len(data)//4))\n",
    "\n",
    "train, test = data.iloc[:-horizon], data.iloc[-horizon:]\n",
    "\n",
    "# Feature set for ML/OLS (avoid leakage: exclude direct future info)\n",
    "exclude_prefixes = ('m_',)\n",
    "exclude_exact = set(['y','y_roll3','y_roll6','y_roll12','y_yoy'])  # keep y_yoy_3m if desired\n",
    "X_cols = [c for c in train.columns if c not in exclude_exact and not any(c.startswith(p) for p in exclude_prefixes)]\n",
    "y_col = 'y'\n",
    "\n",
    "X_train, y_train = train[X_cols], train[y_col]\n",
    "X_test, y_test = test[X_cols], test[y_col]\n",
    "\n",
    "print(f\"Features ({len(X_cols)}):\", X_cols[:12], '...')\n",
    "\n",
    "# 7.1 OLS\n",
    "X_train_c = sm.add_constant(X_train, has_constant='add')\n",
    "ols_model = sm.OLS(y_train, X_train_c).fit()\n",
    "print(ols_model.summary())\n",
    "\n",
    "# 7.2 SARIMAX (simple seasonal guess — adjust as needed)\n",
    "try:\n",
    "    sarimax_mod = tsa.SARIMAX(train[y_col], order=(1,1,1), seasonal_order=(1,1,1,12),\n",
    "                              enforce_stationarity=False, enforce_invertibility=False)\n",
    "    sarimax_fit = sarimax_mod.fit(disp=False)\n",
    "    sarimax_forecast = sarimax_fit.forecast(steps=len(test))\n",
    "except Exception:\n",
    "    sarimax_fit, sarimax_forecast = None, pd.Series(index=y_test.index, dtype=float)\n",
    "\n",
    "# 7.3 Weighted Lag model (example: blend of recent lags)\n",
    "def weighted_lag_predict(train_series, horizon, weights=None):\n",
    "    if weights is None:\n",
    "        # Example: heavier weight on recent months: lags 1,2,3,12\n",
    "        weights = {1:0.45, 2:0.25, 3:0.15, 12:0.15}\n",
    "    preds = []\n",
    "    hist = train_series.copy().tolist()\n",
    "    for _ in range(horizon):\n",
    "        val = 0.0\n",
    "        for lag, w in weights.items():\n",
    "            if len(hist) - lag >= 0:\n",
    "                val += hist[-lag] * w\n",
    "        preds.append(val)\n",
    "        hist.append(val)\n",
    "    return pd.Series(preds, index=test.index)\n",
    "\n",
    "weighted_preds = weighted_lag_predict(train[y_col], horizon=len(test))\n",
    "\n",
    "# 7.4 XGBoost (optional if installed)\n",
    "if XGB_AVAILABLE and len(X_train) > 0 and len(X_test) > 0:\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=300, learning_rate=0.05, max_depth=4,\n",
    "        subsample=0.9, colsample_bytree=0.9, random_state=RANDOM_STATE\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_preds = pd.Series(xgb.predict(X_test), index=y_test.index)\n",
    "else:\n",
    "    xgb_preds = pd.Series(index=y_test.index, dtype=float)\n",
    "\n",
    "# 7.5 Naive 12‑lag + 3‑month YoY growth\n",
    "def naive_12lag_yoy3(train_series, horizon):\n",
    "    preds = []\n",
    "    yoy = (train_series - train_series.shift(12)) / train_series.shift(12)\n",
    "    yoy3 = yoy.rolling(3).mean().iloc[-1]\n",
    "    yoy3 = 0.0 if pd.isna(yoy3) else float(yoy3)\n",
    "    hist = train_series.copy()\n",
    "    for _ in range(horizon):\n",
    "        if len(hist) >= 12:\n",
    "            base = hist.iloc[-12]\n",
    "        else:\n",
    "            base = hist.iloc[-1]\n",
    "        pred = base * (1 + yoy3)\n",
    "        preds.append(pred)\n",
    "        hist = pd.concat([hist, pd.Series([pred])])\n",
    "    return pd.Series(preds, index=test.index)\n",
    "\n",
    "naive_preds = naive_12lag_yoy3(train[y_col], horizon=len(test))\n",
    "\n",
    "# Predictions for OLS and SARIMAX\n",
    "ols_preds = pd.Series(ols_model.predict(sm.add_constant(X_test, has_constant='add')), index=y_test.index)\n",
    "sarimax_preds = sarimax_forecast if sarimax_fit is not None else pd.Series(index=y_test.index, dtype=float)\n",
    "\n",
    "preds_df = pd.DataFrame({\n",
    "    'y_true': y_test,\n",
    "    'OLS': ols_preds,\n",
    "    'SARIMAX': sarimax_preds,\n",
    "    'WeightedLag': weighted_preds,\n",
    "    'XGB' : xgb_preds,\n",
    "    'Naive12LagYoY3': naive_preds\n",
    "})\n",
    "display(preds_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a45fdd0",
   "metadata": {},
   "source": [
    "## 8) Evaluation & Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_all(y_true, pred_dict):\n",
    "    import numpy as np, math\n",
    "    def smape(y_true, y_pred):\n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        denom = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
    "        denom = np.where(denom == 0, 1.0, denom)\n",
    "        return np.mean(np.abs(y_pred - y_true) / denom) * 100\n",
    "    def mape(y_true, y_pred):\n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        denom = np.where(y_true == 0, 1.0, y_true)\n",
    "        return np.mean(np.abs((y_true - y_pred) / denom)) * 100\n",
    "    def mae(y_true, y_pred):\n",
    "        return np.mean(np.abs(np.array(y_true) - np.array(y_pred)))\n",
    "    def rmse(y_true, y_pred):\n",
    "        return math.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))\n",
    "    rows = []\n",
    "    for name, yhat in pred_dict.items():\n",
    "        if len(yhat.dropna()) == 0:\n",
    "            continue\n",
    "        rows.append({\n",
    "            'model': name,\n",
    "            'RMSE': rmse(y_true, yhat),\n",
    "            'MAE': mae(y_true, yhat),\n",
    "            'MAPE': mape(y_true, yhat),\n",
    "            'SMAPE': smape(y_true, yhat)\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values('SMAPE')\n",
    "\n",
    "metrics = eval_all(preds_df['y_true'], {c: preds_df[c].dropna() for c in preds_df.columns if c != 'y_true'})\n",
    "display(metrics)\n",
    "\n",
    "# Plot forecasts vs actuals\n",
    "ax = preds_df[['y_true']].plot(figsize=(10,4), title='Forecast vs Actuals')\n",
    "for c in preds_df.columns:\n",
    "    if c != 'y_true':\n",
    "        preds_df[[c]].plot(ax=ax)\n",
    "ax.grid(True); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487d796d",
   "metadata": {},
   "source": [
    "## 9) Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e16b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_dir = \"/mnt/data/appscope_outputs\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "preds_df.to_csv(os.path.join(out_dir, \"predictions.csv\"), index=True)\n",
    "metrics.to_csv(os.path.join(out_dir, \"metrics.csv\"), index=False)\n",
    "\n",
    "print(\"Saved:\", os.listdir(out_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1075d30",
   "metadata": {},
   "source": [
    "---\n",
    "# Appendix — Original Notebook (verbatim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe915de9",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781d9600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, warnings, pytz, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # keep logs tidy\n",
    "\n",
    "# ------------------- helper-package path --------------------\n",
    "sys.path.append(r\"C:\\WFM_Scripting\\Automation\")  # adjust if needed\n",
    "from scripthelper import Config, Logger, BigQueryManager, EmailManager\n",
    "# ==============================================================================\n",
    "# SECTION 1: DATA SOURCES (QUERIES AND FILE PATHS)\n",
    "# ==============================================================================\n",
    "# Define all queries and file paths\n",
    "sql_tickets_historicals = r\"C:\\WFM_Scripting\\Forecasting\\GBQ - Non-Tax Platform Ticket Timeseries by Month.sql\"\n",
    "sql_workload_driver = \"SELECT MonthOfOrder, client_id, TotalOrders FROM tax_clnt_svcs.view_cx_nontax_platforms_workload_drivers\"\n",
    "sql_fred = \"SELECT Date, UNRATE, HSN1F, FEDFUNDS, MORTGAGE30US FROM tax_clnt_svcs.fred WHERE Date >= '2023-01-01'\"\n",
    "file_market_guidance = r\"C:\\Users\\jhgonzalez\\OneDrive - CoreLogic Solutions, LLC\\Desktop\\Market_G.xlsx\"\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 2: DATA LOADING\n",
    "# ==============================================================================\n",
    "# Initialize the connection manager and load all data sources\n",
    "print(\"Loading data from sources...\")\n",
    "bq_manager = BigQueryManager(Config(rpt_id=9999)) # Use your report ID\n",
    "\n",
    "tickets_historicals = bq_manager.run_gbq_sql(sql_tickets_historicals, return_dataframe=True)\n",
    "workload_driver = bq_manager.run_gbq_sql(sql_workload_driver, return_dataframe=True)\n",
    "FRED = bq_manager.run_gbq_sql(sql_fred, return_dataframe=True)\n",
    "market_guidance = pd.read_excel(file_market_guidance)\n",
    "\n",
    "print(\"All data sources loaded successfully.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 3: MERGING ALL DATA SOURCES\n",
    "# ==============================================================================\n",
    "print(\"\\nMerging all data sources...\")\n",
    "\n",
    "# Prepare workload_driver with special client mappings\n",
    "workload_driver_prep = workload_driver.copy()\n",
    "client_mapping = {\n",
    "    'FNC - CMS': 'FNC',\n",
    "    'FNC - Ports': 'FNC',\n",
    "    'Mercury Integrations': 'Mercury'\n",
    "}\n",
    "workload_driver_prep['client_id'] = workload_driver_prep['client_id'].replace(client_mapping)\n",
    "workload_driver_agg = workload_driver_prep.groupby(['MonthOfOrder', 'client_id'])['TotalOrders'].sum().reset_index()\n",
    "workload_driver_agg = workload_driver_agg.rename(columns={'MonthOfOrder': 'date'})\n",
    "workload_driver_agg['date'] = pd.to_datetime(workload_driver_agg['date'])\n",
    "\n",
    "# Prepare tickets_historicals with a temporary join key for mapping\n",
    "tickets_historicals['date'] = pd.to_datetime(tickets_historicals['date'])\n",
    "tickets_historicals_prep = tickets_historicals.copy()\n",
    "tickets_historicals_prep['join_key'] = tickets_historicals_prep['client_id']\n",
    "fnc_variants = ['FNC - CMS', 'FNC - Ports']\n",
    "tickets_historicals_prep.loc[tickets_historicals_prep['client_id'].isin(fnc_variants), 'join_key'] = 'FNC'\n",
    "mercury_start_date = pd.to_datetime('2023-05-01')\n",
    "mercury_mask = (tickets_historicals_prep['client_id'] == 'Mercury Integrations') & (tickets_historicals_prep['date'] >= mercury_start_date)\n",
    "tickets_historicals_prep.loc[mercury_mask, 'join_key'] = 'Mercury'\n",
    "\n",
    "# Merge tickets with workload\n",
    "merged_df = pd.merge(\n",
    "    tickets_historicals_prep,\n",
    "    workload_driver_agg,\n",
    "    left_on=['date', 'join_key'],\n",
    "    right_on=['date', 'client_id'],\n",
    "    how='left'\n",
    ")\n",
    "merged_df = merged_df.drop(columns=['join_key', 'client_id_y']).rename(columns={'client_id_x': 'client_id'})\n",
    "\n",
    "# Merge with FRED data\n",
    "FRED['Date'] = pd.to_datetime(FRED['Date'])\n",
    "FRED_prep = FRED.rename(columns={'Date': 'date'})\n",
    "final_df = pd.merge(merged_df, FRED_prep, on='date', how='left')\n",
    "\n",
    "# Merge with Market Guidance data\n",
    "market_guidance['DATE'] = pd.to_datetime(market_guidance['DATE'])\n",
    "market_guidance_prep = market_guidance.rename(columns={'DATE': 'date'})\n",
    "final_df = pd.merge(final_df, market_guidance_prep, on='date', how='left')\n",
    "print(\"All merges complete.\")\n",
    "\n",
    "\n",
    "df = final_df\n",
    "# ==============================================================================\n",
    "# SECTION 4: DATA CLEANING (IMPUTATION)\n",
    "# ==============================================================================\n",
    "print(\"\\nCleaning final DataFrame by filling missing values...\")\n",
    "columns_to_fill = [\n",
    "    'UNRATE', 'HSN1F', 'FEDFUNDS', 'MORTGAGE30US',\n",
    "    'Purchase', 'Refinance', 'Year-over-year Variance'\n",
    "]\n",
    "# Forward fill to propagate last known values\n",
    "for col in columns_to_fill:\n",
    "    final_df[col] = final_df[col].ffill()\n",
    "# Backward fill to handle any NaNs at the very start\n",
    "for col in columns_to_fill:\n",
    "    final_df[col] = final_df[col].bfill()\n",
    "print(\"Missing values filled.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 5: SAVE FINAL, CLEANED DATA\n",
    "# ==============================================================================\n",
    "desktop_path = os.path.join(os.path.expanduser('~'), 'Desktop')\n",
    "output_file_path = os.path.join(desktop_path, 'merged_forecasting_data.csv')\n",
    "\n",
    "try:\n",
    "    final_df.to_csv(output_file_path, index=False)\n",
    "    print(f\"\\n✅ DataFrame with all data successfully saved to:\\n{output_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n🔥 An error occurred while saving the file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8164ef05",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c6667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# --- 1. Prepare the Data ---\n",
    "# Ensure 'date' column is in datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Filter for the 'Appraisal Scope' client\n",
    "appraisal_scope_df = df[df['client'] == 'Appraisal Scope'].copy()\n",
    "\n",
    "\n",
    "# --- 2. Create the Plot ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(appraisal_scope_df['date'], appraisal_scope_df['total_cases_opened'], marker='o', linestyle='-')\n",
    "\n",
    "# Formatting the x-axis for readability\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# --- 3. Final Touches ---\n",
    "plt.title('Time Series of Total Cases Opened for Appraisal Scope')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Cases Opened')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43de9fe7",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d11aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Prepare the Data ---\n",
    "# Ensure 'date' column is in datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Filter for the 'Appraisal Scope' client\n",
    "appraisal_scope_df = df[df['client'] == 'Appraisal Scope'].copy()\n",
    "\n",
    "\n",
    "# --- 2. Create the Plot ---\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plotting the primary variable (Total Cases Opened)\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Total Cases Opened', color=color)\n",
    "ax1.plot(appraisal_scope_df['date'], appraisal_scope_df['total_cases_opened'], color=color, marker='o', label='Total Cases Opened')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(True) # Add grid lines for the primary axis\n",
    "\n",
    "# Creating the second y-axis that shares the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Business Day Count', color=color)\n",
    "ax2.plot(appraisal_scope_df['date'], appraisal_scope_df['business_day_count'], color=color, linestyle='--', label='Business Day Count')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Manually set the y-axis limits to ensure variation is visible\n",
    "min_val = appraisal_scope_df['business_day_count'].min()\n",
    "max_val = appraisal_scope_df['business_day_count'].max()\n",
    "ax2.set_ylim(min_val - 1, max_val + 1)\n",
    "\n",
    "# --- 3. Final Touches ---\n",
    "plt.title('Total Cases Opened vs. Business Day Count for Appraisal Scope')\n",
    "fig.tight_layout()\n",
    "# Combine legends from both axes\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80894b67",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e3fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Prepare the Data ---\n",
    "# Ensure 'date' column is in datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Filter for the 'Appraisal Scope' client\n",
    "appraisal_scope_df = df[df['client'] == 'Appraisal Scope'].copy()\n",
    "\n",
    "\n",
    "# --- 2. Create the Plot ---\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plotting the primary variable (Total Cases Opened)\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Total Cases Opened', color=color)\n",
    "ax1.plot(appraisal_scope_df['date'], appraisal_scope_df['total_cases_opened'], color=color, marker='o', label='Total Cases Opened')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(True)\n",
    "\n",
    "# Creating the second y-axis that shares the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:green'\n",
    "ax2.set_ylabel('Total Orders', color=color)\n",
    "ax2.plot(appraisal_scope_df['date'], appraisal_scope_df['TotalOrders'], color=color, linestyle='--', label='Total Orders')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "\n",
    "# --- 3. Final Touches ---\n",
    "plt.title('Total Cases Opened vs. Total Orders for Appraisal Scope')\n",
    "fig.tight_layout()\n",
    "# Combine legends from both axes\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4e6602",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6dc68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Total Cases Opened', color=color)\n",
    "ax1.plot(appraisal_scope_df['date'], appraisal_scope_df['total_cases_opened'], color=color, marker='o', label='Total Cases Opened')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:green'\n",
    "ax2.set_ylabel('UNRATE (%)', color=color)\n",
    "ax2.plot(appraisal_scope_df['date'], appraisal_scope_df['UNRATE'], color=color, linestyle='--', label='UNRATE')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Total Cases Opened vs. Unemployment Rate (UNRATE)')\n",
    "fig.tight_layout()\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cd977f",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edda59fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Total Cases Opened', color=color)\n",
    "ax1.plot(appraisal_scope_df['date'], appraisal_scope_df['total_cases_opened'], color=color, marker='o', label='Total Cases Opened')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:green'\n",
    "ax2.set_ylabel('New Houses Sold (HSN1F)', color=color)\n",
    "ax2.plot(appraisal_scope_df['date'], appraisal_scope_df['HSN1F'], color=color, linestyle='--', label='HSN1F')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Total Cases Opened vs. New Houses Sold (HSN1F)')\n",
    "fig.tight_layout()\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b189361c",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Total Cases Opened', color=color)\n",
    "ax1.plot(appraisal_scope_df['date'], appraisal_scope_df['total_cases_opened'], color=color, marker='o', label='Total Cases Opened')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:olive'\n",
    "ax2.set_ylabel('Federal Funds Rate (%)', color=color)\n",
    "ax2.plot(appraisal_scope_df['date'], appraisal_scope_df['FEDFUNDS'], color=color, linestyle='--', label='FEDFUNDS')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Total Cases Opened vs. Federal Funds Rate')\n",
    "fig.tight_layout()\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a49f615",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Total Cases Opened', color=color)\n",
    "ax1.plot(appraisal_scope_df['date'], appraisal_scope_df['total_cases_opened'], color=color, marker='o', label='Total Cases Opened')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:orange'\n",
    "ax2.set_ylabel('30-Year Mortgage Rate (%)', color=color)\n",
    "ax2.plot(appraisal_scope_df['date'], appraisal_scope_df['MORTGAGE30US'], color=color, linestyle='--', label='MORTGAGE30US')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Total Cases Opened vs. 30-Year Mortgage Rate')\n",
    "fig.tight_layout()\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f1defc",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e3247",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Total Cases Opened', color=color)\n",
    "ax1.plot(appraisal_scope_df['date'], appraisal_scope_df['total_cases_opened'], color=color, marker='o', label='Total Cases Opened')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:brown'\n",
    "ax2.set_ylabel('Purchase Market Guidance', color=color)\n",
    "ax2.plot(appraisal_scope_df['date'], appraisal_scope_df['Purchase'], color=color, linestyle='--', label='Purchase Guidance')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Total Cases Opened vs. Purchase Market Guidance')\n",
    "fig.tight_layout()\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c425e3d1",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f355f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Total Cases Opened', color=color)\n",
    "ax1.plot(appraisal_scope_df['date'], appraisal_scope_df['total_cases_opened'], color=color, marker='o', label='Total Cases Opened')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:green'\n",
    "ax2.set_ylabel('Refinance Market Guidance', color=color)\n",
    "ax2.plot(appraisal_scope_df['date'], appraisal_scope_df['Refinance'], color=color, linestyle='--', label='Refinance Guidance')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Total Cases Opened vs. Refinance Market Guidance')\n",
    "fig.tight_layout()\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16a5890",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dbc60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Total Cases Opened', color=color)\n",
    "ax1.plot(appraisal_scope_df['date'], appraisal_scope_df['total_cases_opened'], color=color, marker='o', label='Total Cases Opened')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:green'\n",
    "ax2.set_ylabel('Year-over-year Variance', color=color)\n",
    "ax2.plot(appraisal_scope_df['date'], appraisal_scope_df['Year-over-year Variance'], color=color, linestyle='--', label='YoY Variance')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Total Cases Opened vs. Year-over-year Variance')\n",
    "fig.tight_layout()\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9efb6a",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb5fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Load and Prepare Data ---\n",
    "# Load the dataset from your local file\n",
    "df = pd.read_csv(r'C:\\Users\\jhgonzalez\\Desktop\\merged_forecasting_data.csv')\n",
    "\n",
    "# Filter for the 'Appraisal Scope' client\n",
    "appraisal_scope_df = df[df['client'] == 'Appraisal Scope'].copy()\n",
    "\n",
    "# --- 2. Clean Data Types (The Fix) ---\n",
    "# Convert the columns to a numeric data type.\n",
    "# errors='coerce' will turn any non-numeric values into NaN (Not a Number).\n",
    "appraisal_scope_df['TotalOrders'] = pd.to_numeric(appraisal_scope_df['TotalOrders'], errors='coerce')\n",
    "appraisal_scope_df['total_cases_opened'] = pd.to_numeric(appraisal_scope_df['total_cases_opened'], errors='coerce')\n",
    "\n",
    "# Drop rows where either of the columns has NaN values after conversion\n",
    "appraisal_scope_df.dropna(subset=['TotalOrders', 'total_cases_opened'], inplace=True)\n",
    "\n",
    "# --- 3. Create the Plot ---\n",
    "# This plotting code will now work correctly with the cleaned data\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(data=appraisal_scope_df, x='TotalOrders', y='total_cases_opened')\n",
    "plt.title('Total Cases Opened vs. Total Orders for Appraisal Scope')\n",
    "plt.xlabel('Total Orders')\n",
    "plt.ylabel('Total Cases Opened')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd49c6ab",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db822fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(data=appraisal_scope_df, x='UNRATE', y='total_cases_opened')\n",
    "plt.title('Total Cases Opened vs. Unemployment Rate (UNRATE)')\n",
    "plt.xlabel('UNRATE (%)')\n",
    "plt.ylabel('Total Cases Opened')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c345716b",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2e7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(data=appraisal_scope_df, x='HSN1F', y='total_cases_opened')\n",
    "plt.title('Total Cases Opened vs. New Houses Sold (HSN1F)')\n",
    "plt.xlabel('New Houses Sold (in Thousands)')\n",
    "plt.ylabel('Total Cases Opened')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede30592",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ae2631",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(data=appraisal_scope_df, x='HSN1F', y='total_cases_opened')\n",
    "plt.title('Total Cases Opened vs. New Houses Sold (HSN1F)')\n",
    "plt.xlabel('New Houses Sold (in Thousands)')\n",
    "plt.ylabel('Total Cases Opened')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71781a1f",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04370e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(data=appraisal_scope_df, x='FEDFUNDS', y='total_cases_opened')\n",
    "plt.title('Total Cases Opened vs. Federal Funds Rate')\n",
    "plt.xlabel('Federal Funds Rate (%)')\n",
    "plt.ylabel('Total Cases Opened')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7c64e",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa29ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(data=appraisal_scope_df, x='Purchase', y='total_cases_opened')\n",
    "plt.title('Total Cases Opened vs. Purchase Market Guidance')\n",
    "plt.xlabel('Purchase Market Guidance')\n",
    "plt.ylabel('Total Cases Opened')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc9ca04",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c1b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(data=appraisal_scope_df, x='Year-over-year Variance', y='total_cases_opened')\n",
    "plt.title('Total Cases Opened vs. Year-over-year Variance')\n",
    "plt.xlabel('Year-over-year Variance')\n",
    "plt.ylabel('Total Cases Opened')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f3caa",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca03e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This script assumes 'appraisal_scope_df' is your prepared DataFrame.\n",
    "\n",
    "# --- 1. Select only numeric columns for the correlation matrix ---\n",
    "numeric_df = appraisal_scope_df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# --- 2. Calculate and print the correlation with the target variable ---\n",
    "# This gives you a direct, sorted list of the most important relationships.\n",
    "target_correlations = numeric_df.corr()['total_cases_opened'].sort_values(ascending=False)\n",
    "print(\"--- Correlation with 'total_cases_opened' ---\")\n",
    "print(target_correlations)\n",
    "\n",
    "# --- 3. Generate the correlation heatmap (table) ---\n",
    "# This provides a full view of how all variables relate to each other.\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap for Appraisal Scope Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b98b47e",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16027aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This script assumes 'appraisal_scope_df' is your prepared DataFrame.\n",
    "# Select only numeric columns for the correlation matrix\n",
    "numeric_df = appraisal_scope_df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calculate the Spearman correlation with the target variable\n",
    "spearman_corr = numeric_df.corr(method='spearman')['total_cases_opened'].sort_values(ascending=False)\n",
    "\n",
    "print(\"--- Spearman's Rank Correlation with 'total_cases_opened' ---\")\n",
    "print(spearman_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841c42d0",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a41f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This script assumes 'appraisal_scope_df' is your prepared DataFrame.\n",
    "# Select only numeric columns for the correlation matrix\n",
    "numeric_df = appraisal_scope_df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calculate the Kendall's Tau correlation with the target variable\n",
    "kendall_corr = numeric_df.corr(method='kendall')['total_cases_opened'].sort_values(ascending=False)\n",
    "\n",
    "print(\"--- Kendall's Tau Correlation with 'total_cases_opened' ---\")\n",
    "print(kendall_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d848b15",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb29506",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# --- 1. Prepare the Data ---\n",
    "# This script assumes 'appraisal_scope_df' is your prepared DataFrame.\n",
    "# The seasonal_decompose function requires a DatetimeIndex.\n",
    "if not isinstance(appraisal_scope_df.index, pd.DatetimeIndex):\n",
    "    appraisal_scope_df['date'] = pd.to_datetime(appraisal_scope_df['date'])\n",
    "    appraisal_scope_df = appraisal_scope_df.set_index('date')\n",
    "\n",
    "\n",
    "# --- 2. Perform and Plot the Decomposition ---\n",
    "# We use a period of 12 because the data is monthly.\n",
    "decomposition = seasonal_decompose(\n",
    "    appraisal_scope_df['total_cases_opened'],\n",
    "    model='additive',\n",
    "    period=12\n",
    ")\n",
    "\n",
    "# The .plot() method automatically creates a figure with the four components\n",
    "fig = decomposition.plot()\n",
    "fig.set_size_inches(12, 8)\n",
    "plt.suptitle('Seasonal Decomposition of Total Cases Opened', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7995057e",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbca69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# This script assumes 'appraisal_scope_df' is your prepared DataFrame.\n",
    "\n",
    "# --- 1. Prepare the Data ---\n",
    "# The adfuller function requires a series with no missing values.\n",
    "target_series = appraisal_scope_df['total_cases_opened'].dropna()\n",
    "\n",
    "# --- 2. Perform the ADF Test ---\n",
    "result = adfuller(target_series)\n",
    "\n",
    "# --- 3. Print and Interpret the Results ---\n",
    "print('--- Augmented Dickey-Fuller Test Results ---')\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "    print(f'\\t{key}: {value}')\n",
    "\n",
    "print(\"\\n--- Conclusion ---\")\n",
    "if result[1] <= 0.05:\n",
    "    print(\"The p-value is less than 0.05, so we reject the null hypothesis.\")\n",
    "    print(\"Result: The data is likely stationary.\")\n",
    "else:\n",
    "    print(\"The p-value is greater than 0.05, so we fail to reject the null hypothesis.\")\n",
    "    print(\"Result: The data is likely non-stationary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98d4cde",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c03e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# --- 1. Load and Prepare Data ---\n",
    "df = pd.read_csv(r'C:\\Users\\jhgonzalez\\Desktop\\merged_forecasting_data.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.set_index('date')\n",
    "appraisal_scope_df = df[df['client'] == 'Appraisal Scope'].copy()\n",
    "\n",
    "# --- 2. Feature Engineering & Final Selection ---\n",
    "appraisal_scope_df['month'] = appraisal_scope_df.index.month\n",
    "features = ['TotalOrders', 'business_day_count'] # Using the final recommended features\n",
    "target = 'total_cases_opened'\n",
    "appraisal_scope_df = appraisal_scope_df.dropna(subset=[target] + features)\n",
    "\n",
    "# --- 3. Split Data ---\n",
    "X = appraisal_scope_df[features]\n",
    "y = appraisal_scope_df[target]\n",
    "split_point = len(appraisal_scope_df) - 6\n",
    "X_train = X.iloc[:split_point]\n",
    "y_train = y.iloc[:split_point]\n",
    "\n",
    "# --- 4. Fit the OLS Model ---\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "model_sm = sm.OLS(y_train, X_train_sm).fit()\n",
    "residuals = model_sm.resid\n",
    "\n",
    "print(\"OLS model has been fitted. Residuals are ready for testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198f58cb",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47706b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# Perform the Ljung-Box test on the model's residuals\n",
    "ljung_box_results = acorr_ljungbox(residuals, lags=[12], return_df=True)\n",
    "\n",
    "print(\"--- Ljung-Box Test for Autocorrelation in Residuals ---\")\n",
    "print(ljung_box_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffeec1c",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Perform the Shapiro-Wilk test on the residuals\n",
    "shapiro_test = shapiro(residuals)\n",
    "\n",
    "print(\"\\n--- Shapiro-Wilk Test for Normality of Residuals ---\")\n",
    "print(f\"Test Statistic: {shapiro_test.statistic}\")\n",
    "print(f\"P-value: {shapiro_test.pvalue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4059c286",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd9411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "# The test requires a DataFrame with the two time series\n",
    "causality_df = appraisal_scope_df[['total_cases_opened', 'TotalOrders']].dropna()\n",
    "\n",
    "# Perform the test. We'll test up to a lag of 3 months.\n",
    "granger_results = grangercausalitytests(causality_df, maxlag=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd2a308",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4122861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Function to Calculate SMAPE ---\n",
    "def smape(y_true, y_pred):\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    return np.mean(numerator / denominator) * 100\n",
    "\n",
    "# --- 1. Load and Prepare Data ---\n",
    "df = pd.read_csv(r'C:\\Users\\jhgonzalez\\Desktop\\merged_forecasting_data.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.set_index('date')\n",
    "appraisal_scope_df = df[df['client'] == 'Appraisal Scope'].copy()\n",
    "\n",
    "# --- 2. Feature Engineering ---\n",
    "# Create lagged features based on Granger Causality results\n",
    "appraisal_scope_df['TotalOrders_lag_2'] = appraisal_scope_df['TotalOrders'].shift(2)\n",
    "appraisal_scope_df['TotalOrders_lag_3'] = appraisal_scope_df['TotalOrders'].shift(3)\n",
    "\n",
    "# Define features and target, and drop rows with missing values from lagging\n",
    "features = ['business_day_count', 'TotalOrders_lag_2', 'TotalOrders_lag_3']\n",
    "target = 'total_cases_opened'\n",
    "appraisal_scope_df = appraisal_scope_df.dropna(subset=[target] + features)\n",
    "\n",
    "# --- 3. Select Features and Split Data ---\n",
    "X = appraisal_scope_df[features]\n",
    "y = appraisal_scope_df[target]\n",
    "\n",
    "# Split the data to test on the last 6 months\n",
    "split_point = len(appraisal_scope_df) - 6\n",
    "X_train = X.iloc[:split_point]\n",
    "y_train = y.iloc[:split_point]\n",
    "X_test = X.iloc[split_point:]\n",
    "y_test = y.iloc[split_point:]\n",
    "\n",
    "# --- 4. Build and Train the SARIMAX Model ---\n",
    "# The (p,d,q) and (P,D,Q,s) orders are hyperparameters.\n",
    "# These are common starting points for monthly, seasonal data.\n",
    "model = SARIMAX(y_train,\n",
    "                exog=X_train,\n",
    "                order=(1, 1, 1),\n",
    "                seasonal_order=(1, 1, 0, 12))\n",
    "\n",
    "results = model.fit(disp=False)\n",
    "print(results.summary())\n",
    "\n",
    "\n",
    "# --- 5. Make Predictions and Evaluate ---\n",
    "predictions = results.get_forecast(steps=len(X_test), exog=X_test)\n",
    "predicted_mean = predictions.predicted_mean\n",
    "\n",
    "mae = mean_absolute_error(y_test, predicted_mean)\n",
    "smape_error = smape(y_test, predicted_mean)\n",
    "\n",
    "print(\"\\n--- SARIMAX Model Evaluation (Last 6 Months) ---\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Symmetric Mean Absolute Percentage Error (SMAPE): {smape_error:.2f}%\")\n",
    "\n",
    "\n",
    "# --- 6. Visualize the Results ---\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(appraisal_scope_df.index, appraisal_scope_df[target], label='Actual Cases')\n",
    "plt.plot(predicted_mean.index, predicted_mean.values, label='SARIMAX Forecast', linestyle='--')\n",
    "plt.title('Actual vs. SARIMAX Forecast for Appraisal Scope')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Cases Opened')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeca0128",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8bf066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# --- Function to Calculate SMAPE ---\n",
    "def smape(y_true, y_pred):\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    return np.mean(numerator / denominator) * 100\n",
    "\n",
    "# --- 1. Load and Prepare Data ---\n",
    "df = pd.read_csv(r'C:\\Users\\jhgonzalez\\Desktop\\merged_forecasting_data.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.set_index('date')\n",
    "appraisal_scope_df = df[df['client'] == 'Appraisal Scope'].copy()\n",
    "\n",
    "# --- 2. Feature Engineering ---\n",
    "appraisal_scope_df['month'] = appraisal_scope_df.index.month\n",
    "features = ['TotalOrders', 'business_day_count', 'month']\n",
    "target = 'total_cases_opened'\n",
    "appraisal_scope_df = appraisal_scope_df.dropna(subset=[target] + features)\n",
    "\n",
    "# --- 3. Select Features and Split Data ---\n",
    "X = appraisal_scope_df[features]\n",
    "y = appraisal_scope_df[target]\n",
    "\n",
    "# Split the data to test on the last 6 months\n",
    "split_point = len(appraisal_scope_df) - 6\n",
    "X_train = X.iloc[:split_point]\n",
    "y_train = y.iloc[:split_point]\n",
    "X_test = X.iloc[split_point:]\n",
    "y_test = y.iloc[split_point:]\n",
    "\n",
    "# --- 4. Build, Train, and Evaluate ---\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "smape_error = smape(y_test, predictions)\n",
    "\n",
    "print(\"--- OLS Model Evaluation (Last 6 Months) ---\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Symmetric Mean Absolute Percentage Error (SMAPE): {smape_error:.2f}%\")\n",
    "\n",
    "# --- 5. Generate Detailed Statistical Summary ---\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "model_sm = sm.OLS(y_train, X_train_sm).fit()\n",
    "print(\"\\n--- OLS Regression Statistical Summary ---\")\n",
    "print(model_sm.summary())\n",
    "\n",
    "# --- 6. Visualize the Results ---\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(appraisal_scope_df.index, appraisal_scope_df[target], label='Actual Cases')\n",
    "plt.plot(X_test.index, predictions, label='OLS Forecast', linestyle='--')\n",
    "plt.title('Actual vs. OLS Forecast for Appraisal Scope (Last 6 Months Test)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Cases Opened')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fb8c83",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852696a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# --- Function to Calculate SMAPE ---\n",
    "def smape(y_true, y_pred):\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    return np.mean(numerator / denominator) * 100\n",
    "\n",
    "# --- 1. Load and Prepare Data ---\n",
    "df = pd.read_csv(r'C:\\Users\\jhgonzalez\\Desktop\\merged_forecasting_data.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.set_index('date')\n",
    "appraisal_scope_df = df[df['client'] == 'Appraisal Scope'].copy()\n",
    "target = 'total_cases_opened'\n",
    "\n",
    "# --- 2. Feature Engineering ---\n",
    "# Use the [1, 12] lag combination for momentum and seasonality\n",
    "df_lagged = appraisal_scope_df.copy()\n",
    "df_lagged['lag_1'] = df_lagged[target].shift(1)\n",
    "df_lagged['lag_12'] = df_lagged[target].shift(12)\n",
    "df_lagged = df_lagged.dropna()\n",
    "\n",
    "# --- 3. Select Features and Split Data ---\n",
    "features = ['lag_1', 'lag_12']\n",
    "X = df_lagged[features]\n",
    "y = df_lagged[target]\n",
    "\n",
    "# Split the data to test on the last 6 months\n",
    "split_point = len(df_lagged) - 6\n",
    "X_train = X.iloc[:split_point]\n",
    "y_train = y.iloc[:split_point]\n",
    "X_test = X.iloc[split_point:]\n",
    "y_test = y.iloc[split_point:]\n",
    "\n",
    "# --- 4. Build, Train, and Evaluate ---\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "smape_error = smape(y_test, predictions)\n",
    "\n",
    "print(\"--- Weighted Lag Average Model Evaluation (Last 6 Months) ---\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Symmetric Mean Absolute Percentage Error (SMAPE): {smape_error:.2f}%\")\n",
    "\n",
    "# --- 5. Generate Detailed Statistical Summary ---\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "model_sm = sm.OLS(y_train, X_train_sm).fit()\n",
    "print(\"\\n--- OLS Regression Statistical Summary ---\")\n",
    "print(model_sm.summary())\n",
    "\n",
    "# --- 6. Visualize the Results ---\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_lagged.index, df_lagged[target], label='Actual Cases')\n",
    "plt.plot(X_test.index, predictions, label='Forecast', linestyle='--')\n",
    "plt.title('Actual vs. Forecast (Weighted Lag Average Model)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Cases Opened')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd4b6c",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5b6a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c91c8ad",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9874195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1075f38",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c555318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9656f4da",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8898c07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8aea889",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d02833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c766386",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffaaa99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d5ffcbb",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c3700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e1462ab",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab9c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a736c870",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd15699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c8f5e19",
   "metadata": {},
   "source": [
    "**(Original) Code Cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872daee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
